{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive bayes is on bayes theorem: <br> <center>\n",
    "Bayes theorem = p(a|b) = (p(b|a)*p(a))/p(b)\n",
    "</br> </center> <br>\n",
    "In our case a will be target label and b is feature vector. We will assume all feature are mutually independent. <br>In our dataset [Source: https://www.kaggle.com/msjaiclub/2classclassification?select=ex2data1.csv] a person being healthy or not is our target and features are person-go-for-walk and person-eat-healthy-food so both are independent but both contribute in target.\n",
    "\n",
    "using that independent assumption now we can divide probability for every feature by converting <br> <center>\n",
    "    <b>p(a|b) = { (p(b1|a)*p(b2|a)*p(b3|a)....*p(bn|a)) * p(a) } / p(b) </b>\n",
    "    </br> </center>\n",
    "<br>\n",
    "where p(a|b) is posterior probability <br>\n",
    "p(b1|a) is class conditional probability <br>\n",
    "p(a) = prior prob of a <br>\n",
    "p(b) = prior prob of b <br>\n",
    "\n",
    "Now we will select class which is highest so we will apply <br> <center> \n",
    " <b>argmax a {p(a|b)} <br> or <br> argmax a { (p(b1|a)*p(b2|a)*p(b3|a)....*p(bn|a)) * p(a) } / p(b) </b> <br> </center> <br>\n",
    "and we will take log of this multiplication because this all term is between 0 to 1 can cause overflow so convert it by taking log.\n",
    "\n",
    "So final formula becomes <b> <br> <center> argmax a {log(p(b1|a)) + .... + log(p(bn|a) + log(p(a)) } </center> <br>  </b>\n",
    "where prior prob p(a) is just frequency <br>\n",
    "and class conditional p(bi|a) for all i = 1...n features follows gaussian kernel.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "\n",
    "    def fittodata(self, data, target):\n",
    "        samples, features = data.shape       #shape function give no. of row and column\n",
    "        self._classes = np.unique(target)    #diffrent element in target array\n",
    "        classes = len(self._classes)         #number of classes\n",
    "        #  # calculate mean, var, and prior for each class.\n",
    "        self._mean = np.zeros((classes, features), dtype=np.float64)  #intialise mean var to zeros for each class and its feature\n",
    "        self._var = np.zeros((classes, features), dtype=np.float64)\n",
    "        self._priors =  np.zeros(classes, dtype=np.float64)    #for each class a prior neede and its initialise to zero\n",
    "\n",
    "        for i, c in enumerate(self._classes):  #doing for every unique class\n",
    "            data_c = data[target==c]  # we select all data with one class like all data with target 0\n",
    "            self._mean[i, :] = data_c.mean(axis=0)  #we want to take mean and var for each class.\n",
    "            self._var[i, :] = data_c.var(axis=0)\n",
    "            self._priors[i] = data_c.shape[0] / float(samples) #we get sample with this label divide by all samples\n",
    "\n",
    "    def predictdata(self, data):   #PREDICT FOR WHOLE SAMPLE\n",
    "        target_pred = [self._predictdata(x) for x in data]\n",
    "        return np.array(target_pred)\n",
    "      \n",
    "        \n",
    "        # calculate posterior probability for each class\n",
    "    def _predictdata(self, x):  # PREDICT OF EACH DATA AND USED AGAIN IN ABOVE\n",
    "        posteriors = []\n",
    "        for i, c in enumerate(self._classes):  # ENUMERATE GENERATE INDEX ALSO\n",
    "            prior = np.log(self._priors[i])\n",
    "            posterior = np.sum(np.log(self._pdfdata(i, x)))\n",
    "            posterior = prior + posterior\n",
    "            posteriors.append(posterior)\n",
    "            \n",
    "            # return class with highest posterior probability\n",
    "        return self._classes[np.argmax(posteriors)]\n",
    "            \n",
    "\n",
    "    def _pdfdata(self, class_i, x): #THIS IS PROBABILITY DENSITY FUNCTION\n",
    "        mean = self._mean[class_i]\n",
    "        var = self._var[class_i]\n",
    "        num = np.exp(- (x-mean)**2 / (2 * var))\n",
    "        deno = np.sqrt(2 * np.pi * var)\n",
    "        return num / deno\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ex2data1.csv') #we have taken a dataset from kaggle[https://www.kaggle.com/msjaiclub/2classclassification?select=ex2data1.csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.623660</td>\n",
       "      <td>78.024693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.286711</td>\n",
       "      <td>43.894998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.847409</td>\n",
       "      <td>72.902198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.182599</td>\n",
       "      <td>86.308552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.032736</td>\n",
       "      <td>75.344376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x          y  label\n",
       "0  34.623660  78.024693      0\n",
       "1  30.286711  43.894998      0\n",
       "2  35.847409  72.902198      0\n",
       "3  60.182599  86.308552      1\n",
       "4  79.032736  75.344376      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # dataset head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop('label',axis = 1) # in data we take all column except target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(data)  # converting that to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34.62365962, 78.02469282],\n",
       "       [30.28671077, 43.89499752],\n",
       "       [35.84740877, 72.90219803],\n",
       "       [60.18259939, 86.3085521 ],\n",
       "       [79.03273605, 75.34437644],\n",
       "       [45.08327748, 56.31637178],\n",
       "       [61.10666454, 96.51142588],\n",
       "       [75.02474557, 46.55401354],\n",
       "       [76.0987867 , 87.42056972],\n",
       "       [84.43281996, 43.53339331],\n",
       "       [95.86155507, 38.22527806],\n",
       "       [75.01365839, 30.60326323],\n",
       "       [82.30705337, 76.4819633 ],\n",
       "       [69.36458876, 97.71869196],\n",
       "       [39.53833914, 76.03681085],\n",
       "       [53.97105215, 89.20735014],\n",
       "       [69.07014406, 52.74046973],\n",
       "       [67.94685548, 46.67857411],\n",
       "       [70.66150955, 92.92713789],\n",
       "       [76.97878373, 47.57596365],\n",
       "       [67.37202755, 42.83843832],\n",
       "       [89.67677575, 65.79936593],\n",
       "       [50.53478829, 48.85581153],\n",
       "       [34.21206098, 44.2095286 ],\n",
       "       [77.92409145, 68.97235999],\n",
       "       [62.27101367, 69.95445795],\n",
       "       [80.19018075, 44.82162893],\n",
       "       [93.1143888 , 38.80067034],\n",
       "       [61.83020602, 50.25610789],\n",
       "       [38.7858038 , 64.99568096],\n",
       "       [61.37928945, 72.80788731],\n",
       "       [85.40451939, 57.05198398],\n",
       "       [52.10797973, 63.12762377],\n",
       "       [52.04540477, 69.43286012],\n",
       "       [40.23689374, 71.16774802],\n",
       "       [54.63510555, 52.21388588],\n",
       "       [33.91550011, 98.86943574],\n",
       "       [64.17698887, 80.90806059],\n",
       "       [74.78925296, 41.57341523],\n",
       "       [34.18364003, 75.23772034],\n",
       "       [83.90239366, 56.30804622],\n",
       "       [51.54772027, 46.85629026],\n",
       "       [94.44336777, 65.56892161],\n",
       "       [82.36875376, 40.61825516],\n",
       "       [51.04775177, 45.82270146],\n",
       "       [62.22267576, 52.06099195],\n",
       "       [77.19303493, 70.4582    ],\n",
       "       [97.77159928, 86.72782233],\n",
       "       [62.0730638 , 96.76882412],\n",
       "       [91.5649745 , 88.69629255],\n",
       "       [79.94481794, 74.16311935],\n",
       "       [99.27252693, 60.999031  ],\n",
       "       [90.54671411, 43.39060181],\n",
       "       [34.52451385, 60.39634246],\n",
       "       [50.28649612, 49.80453881],\n",
       "       [49.58667722, 59.80895099],\n",
       "       [97.64563396, 68.86157272],\n",
       "       [32.57720017, 95.59854761],\n",
       "       [74.24869137, 69.82457123],\n",
       "       [71.79646206, 78.45356225],\n",
       "       [75.39561147, 85.75993667],\n",
       "       [35.28611282, 47.02051395],\n",
       "       [56.2538175 , 39.26147251],\n",
       "       [30.05882245, 49.59297387],\n",
       "       [44.66826172, 66.45008615],\n",
       "       [66.56089447, 41.09209808],\n",
       "       [40.45755098, 97.53518549],\n",
       "       [49.07256322, 51.88321182],\n",
       "       [80.27957401, 92.11606081],\n",
       "       [66.74671857, 60.99139403],\n",
       "       [32.72283304, 43.30717306],\n",
       "       [64.03932042, 78.03168802],\n",
       "       [72.34649423, 96.22759297],\n",
       "       [60.45788574, 73.0949981 ],\n",
       "       [58.84095622, 75.85844831],\n",
       "       [99.8278578 , 72.36925193],\n",
       "       [47.26426911, 88.475865  ],\n",
       "       [50.4581598 , 75.80985953],\n",
       "       [60.45555629, 42.50840944],\n",
       "       [82.22666158, 42.71987854],\n",
       "       [88.91389642, 69.8037889 ],\n",
       "       [94.83450672, 45.6943068 ],\n",
       "       [67.31925747, 66.58935318],\n",
       "       [57.23870632, 59.51428198],\n",
       "       [80.366756  , 90.9601479 ],\n",
       "       [68.46852179, 85.5943071 ],\n",
       "       [42.07545454, 78.844786  ],\n",
       "       [75.47770201, 90.424539  ],\n",
       "       [78.63542435, 96.64742717],\n",
       "       [52.34800399, 60.76950526],\n",
       "       [94.09433113, 77.15910509],\n",
       "       [90.44855097, 87.50879176],\n",
       "       [55.48216114, 35.57070347],\n",
       "       [74.49269242, 84.84513685],\n",
       "       [89.84580671, 45.35828361],\n",
       "       [83.48916274, 48.3802858 ],\n",
       "       [42.26170081, 87.10385094],\n",
       "       [99.31500881, 68.77540947],\n",
       "       [55.34001756, 64.93193801],\n",
       "       [74.775893  , 89.5298129 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['label'] # target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.asarray(target) # convert to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, target_train, target_test = train_test_split(data,target,test_size = 0.2 ,random_state = 42)  # splitting in train test split with 80/20 ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(target_true, target_pred): # accuracy by checking if prediction match the actual target label\n",
    "    accuracy = np.sum(target_true == target_pred) / len(target_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayesClassifier() # just named nb for shortform\n",
    "nb.fittodata(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nb.predictdata(data_test) # prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes classification accuracy 0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes classification accuracy\", accuracy(target_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
